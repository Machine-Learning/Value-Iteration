Task 2:
    Case 1: In this case, not much change is observed in our policy. This is because Indiana Jones in Task 1 policy tried to avoid CENTER pos, as it makes him vulnerable to attack from Mighty Monster. Similar pattern is observed here as well.
    The number of iterations in this case remain almost same ().
    
    Case 2: In this case, STAY action seems to become a better choice for Indiana Jones in the WEST pos.
    The number of iterations required for convergence here are

    Case 3: Due to lower value of GAMMA, future rewards become less valuable, and as a result, the convergence occurs in much less iterations ().
